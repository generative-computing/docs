---
title: Session
sidebar_label: Session
---

# Module: `session`

Mellea Sessions.

## Functions

### `backend_name_to_class(name)`

Resolves backend names to Backend classes.

---

### `start_session(backend_name, model_id, ctx, **backend_kwargs)`

Helper for starting a new mellea session.

Args:
backend_name (str): ollama | hf | openai
model_id (ModelIdentifier): a `ModelIdentifier` from the mellea.backends.model_ids module
ctx (Optional[Context]): If not provided, a `LinearContext` is used.
model_options (Optional[dict]): Backend will be instantiated with these as its default, if provided.
backend_kwargs: kwargs that will be passed to the backend for instantiation.

---

## Classes

### `class MelleaSession`

Mellea sessions are a THIN wrapper around `m` convenience functions with NO special semantics.

Using a Mellea session is not required, but it does represent the "happy path" of Mellea programming. Some nice things about ussing a `MelleaSession`:
1. In most cases you want to keep a Context together with the Backend from which it came.
2. You can directly run an instruction or a send a chat, instead of first creating the `Instruction` or `Chat` object and then later calling backend.generate on the object.
3. The context is "threaded-through" for you, which allows you to issue a sequence of commands instead of first calling backend.generate on something and then appending it to your context.

These are all relatively simple code hygiene and state management benefits, but they add up over time.
If you are doing complicating programming (e.g., non-trivial inference scaling) then you might be better off forgoing `MelleaSession`s and managing your Context and Backend directly.

Note: we put the `instruct`, `validate`, and other convenience functions here instead of in `Context` or `Backend` to avoid import resolution issues.

#### Methods

##### `__init__(self, backend, ctx)`

Initializes a new Mellea session with the provided backend and context.

Args:
backend (Backend): This is always required.
ctx (Context): The way in which the model's context will be managed. By default, each interaction with the model is a stand-alone interaction, so we use SimpleContext as the default.
model_options (Optional[dict]): model options, which will upsert into the model/backend's defaults.

-----

##### `_push_model_state(self, new_backend, new_model_opts)`

The backend and model options used within a `Context` can be temporarily changed. This method changes the model's backend and model_opts, while saving the current settings in the `self._backend_stack`.

Question: should this logic be moved into context? I really want to keep `Session` as simple as possible... see true motivation in the docstring for the class.

-----

##### `_pop_model_state(self)`

Pops the model state.

The backend and model options used within a `Context` can be temporarily changed by pushing and popping from the model state.
This function restores the model's previous backend and model_opts from the `self._backend_stack`.

Question: should this logic be moved into context? I really want to keep `Session` as simple as possible... see true motivation in the docstring for the class.

-----

##### `reset(self)`

Reset the context state.

-----

##### `summarize(self)`

Summarizes the current context.

-----

##### `instruct(self, description)`

Generates from an instruction.

Args:
description: The description of the instruction.
requirements: A list of requirements that the instruction can be validated against.
icl_examples: A list of in-context-learning examples that the instruction can be validated against.
grounding_context: A list of grounding contexts that the instruction can use. They can bind as variables using a (key: str, value: str | ContentBlock) tuple.
user_variables: A dict of user-defined variables used to fill in Jinja placeholders in other parameters. This requires that all other provided parameters are provided as strings.
prefix: A prefix string or ContentBlock to use when generating the instruction.
output_prefix: A string or ContentBlock that defines a prefix for the output generation. Usually you do not need this.
strategy: A SamplingStrategy that describes the strategy for validating and repairing/retrying for the instruct-validate-repair pattern. None means that no particular sampling strategy is used.
return_sampling_results: attach the (successful and failed) sampling attempts to the results.
format: If set, the BaseModel to use for constrained decoding.
model_options: Additional model options, which will upsert into the model/backend's defaults.
tool_calls: If true, tool calling is enabled.

-----

##### `chat(self, content, role)`

Sends a simple chat message and returns the response. Adds both messages to the Context.

-----

##### `act(self, c, tool_calls)`

Runs a generic action, and adds both the action and the result to the context.

-----

##### `validate(self, reqs)`

Validates a set of requirements over the output (if provided) or the current context (if the output is not provided).

-----

##### `req(self, *args, **kwargs)`

Shorthand for Requirement.__init__(...).

-----

##### `check(self, *args, **kwargs)`

Shorthand for Requirement.__init__(..., check_only=True).

-----

##### `load_default_aloras(self)`

Loads the default Aloras for this model, if they exist and if the backend supports.

-----

##### `genslot(self, gen_slot, model_options, format, tool_calls)`

Call generative Slot on a GenerativeSlot Component.

Args:
gen_slot (GenerativeSlot Component): A generative slot

Returns:
ModelOutputThunk: Output thunk

-----

##### `query(self, obj, query)`

Query method for retrieving information from an object.

Args:
obj : The object to be queried. It should be an instance of MObject or can be converted to one if necessary.
query:  The string representing the query to be executed against the object.
format:  format for output parsing.
model_options: Model options to pass to the backend.
tool_calls: If true, the model may make tool calls. Defaults to False.

Returns:
ModelOutputThunk: The result of the query as processed by the backend.

-----

##### `transform(self, obj, transformation)`

Transform method for creating a new object with the transformation applied.

Args:
obj : The object to be queried. It should be an instance of MObject or can be converted to one if necessary.
transformation:  The string representing the query to be executed against the object.

Returns:
ModelOutputThunk|Any: The result of the transformation as processed by the backend. If no tools were called,
the return type will be always be ModelOutputThunk. If a tool was called, the return type will be the return type
of the function called, usually the type of the object passed in.

-----

##### `_call_tools(self, result)`

Call all the tools requested in a result's tool calls object.

Returns:
list[ToolMessage]: A list of tool messages that can be empty.

-----

##### `last_prompt(self)`

Returns the last prompt that has been called from the session context.

Returns:
A string if the last prompt was a raw call to the model OR a list of messages (as role-msg-dicts). Is None if none could be found.

-----

---
